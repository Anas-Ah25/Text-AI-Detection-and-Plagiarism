{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 6890527,
          "sourceType": "datasetVersion",
          "datasetId": 3942644
        },
        {
          "sourceId": 11763143,
          "sourceType": "datasetVersion",
          "datasetId": 7384805
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anas-Ah25/Text-AI-Detection-and-Plagiarism/blob/main/notebooks/distilbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "kK_reuPnYESm"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "thedrcat_daigt_proper_train_dataset_path = kagglehub.dataset_download('thedrcat/daigt-proper-train-dataset')\n",
        "tasneemmahmed_distilbert_model_pth_path = kagglehub.dataset_download('tasneemmahmed/distilbert-model-pth')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "JNRuz7mzYESn"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T14:51:34.267805Z",
          "iopub.execute_input": "2025-05-10T14:51:34.268026Z",
          "iopub.status.idle": "2025-05-10T14:52:01.022737Z",
          "shell.execute_reply.started": "2025-05-10T14:51:34.268009Z",
          "shell.execute_reply": "2025-05-10T14:52:01.02187Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "OJfG5oU4YESo",
        "outputId": "79c99bff-d814-47fb-98ad-a57f00cdd6bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset,  DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertModel\n",
        "from transformers import DistilBertTokenizer\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T15:36:19.46363Z",
          "iopub.execute_input": "2025-05-10T15:36:19.463928Z",
          "iopub.status.idle": "2025-05-10T15:36:19.468056Z",
          "shell.execute_reply.started": "2025-05-10T15:36:19.463906Z",
          "shell.execute_reply": "2025-05-10T15:36:19.467332Z"
        },
        "id": "xBF5PRMtYESp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T15:24:54.927463Z",
          "iopub.execute_input": "2025-05-10T15:24:54.92797Z",
          "iopub.status.idle": "2025-05-10T15:24:54.931317Z",
          "shell.execute_reply.started": "2025-05-10T15:24:54.927951Z",
          "shell.execute_reply": "2025-05-10T15:24:54.930614Z"
        },
        "id": "xoExZzY1YESq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# load DAIGT dataset\n",
        "data_dir = '/kaggle/input/daigt-proper-train-dataset'\n",
        "\n",
        "all_files = [f for f in os.listdir(data_dir)]\n",
        "all_files.sort()\n",
        "\n",
        "# concatenate\n",
        "df_list = []\n",
        "for file in all_files:\n",
        "    file_path = os.path.join(data_dir, file)\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df[['text', 'label']]\n",
        "    df_list.append(df)\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T15:24:56.476542Z",
          "iopub.execute_input": "2025-05-10T15:24:56.4768Z",
          "iopub.status.idle": "2025-05-10T15:25:01.15546Z",
          "shell.execute_reply.started": "2025-05-10T15:24:56.476779Z",
          "shell.execute_reply": "2025-05-10T15:25:01.154808Z"
        },
        "id": "iTjCV5RDYESr",
        "outputId": "9903b877-a407-4e93-b313-353debd29479"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                                                text  label\n0  There are alot reasons to keep our the despise...      0\n1  Driving smart cars that drive by themself has ...      0\n2  Dear Principal,\\n\\nI believe that students at ...      0\n3  Dear Principal,\\n\\nCommunity service should no...      0\n4  My argument for the development of the driverl...      0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:01:12.014823Z",
          "iopub.execute_input": "2025-05-10T16:01:12.015547Z",
          "iopub.status.idle": "2025-05-10T16:01:12.019939Z",
          "shell.execute_reply.started": "2025-05-10T16:01:12.015524Z",
          "shell.execute_reply": "2025-05-10T16:01:12.019364Z"
        },
        "id": "eF5a-PuXYESr",
        "outputId": "823c7cd9-2d1e-4995-bb5b-117c2402764e"
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "159456"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 40,000 from each class\n",
        "class_0 = df[df['label'] == 0]\n",
        "class_1 = df[df['label'] == 1]\n",
        "\n",
        "sample_size = 40000\n",
        "\n",
        "sample_0 = class_0.sample(n=sample_size, random_state=42, replace=False)\n",
        "sample_1 = class_1.sample(n=sample_size, random_state=42, replace=False)\n",
        "\n",
        "df_sampled = pd.concat([sample_0, sample_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(df_sampled['label'].value_counts())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:17:20.243807Z",
          "iopub.execute_input": "2025-05-10T16:17:20.244073Z",
          "iopub.status.idle": "2025-05-10T16:17:20.291974Z",
          "shell.execute_reply.started": "2025-05-10T16:17:20.244055Z",
          "shell.execute_reply": "2025-05-10T16:17:20.291347Z"
        },
        "id": "wqstH03zYESs",
        "outputId": "83f4f735-9c35-4ffd-fc4a-968a8e01b91a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "label\n1    40000\n0    40000\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df_sampled['text'].tolist(),\n",
        "    df_sampled['label'].tolist(),\n",
        "    test_size=0.2,\n",
        "    stratify=df_sampled['label'],\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:17.188301Z",
          "iopub.execute_input": "2025-05-10T16:18:17.188775Z",
          "iopub.status.idle": "2025-05-10T16:18:17.245381Z",
          "shell.execute_reply.started": "2025-05-10T16:18:17.188753Z",
          "shell.execute_reply": "2025-05-10T16:18:17.244862Z"
        },
        "id": "kAve0wPwYESt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:19.46288Z",
          "iopub.execute_input": "2025-05-10T16:18:19.463183Z",
          "iopub.status.idle": "2025-05-10T16:18:19.467758Z",
          "shell.execute_reply.started": "2025-05-10T16:18:19.463165Z",
          "shell.execute_reply": "2025-05-10T16:18:19.46714Z"
        },
        "id": "956NyCprYESt",
        "outputId": "712e5bb6-cb1e-4528-b393-569205f49cdd"
      },
      "outputs": [
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/plain": "\"To the Principal,\\n\\nI think you are trying to do the write thing by not allowing kids under a grade B participate in any after school sports even though most kids in this school have a C average. I feel that if you say you need to get a B average to play sports that would be the write thing to do. It's smart to make kids get better grades to participate in after school sports because if they really want to do the sports then there going to want to get better grades and to do well in school.\\n\\nIts great for the school and its great for the students to get great grades.\\n\\nThe students that do not agree with this policy will not earn the right to play sports, so its either get good grades and play or get bad grades and not play.\\n\\nYou could reduce the amount of kids that do not agree with this policy maybe if you don't make it sound like a challenge and you make it sound fun to get B' s in school You could even hold an after school sports activity for getting the highest grade in your class and hold a competition amongst these students. Also good grades also lead to good behavior so that is another reason to stick with your policy. This might even make school a fun place for students who hate it or think it's boring.\\n\\nIn the future you should try to get students with B pluses and A' s to play in school sports so you keep pushing them to get the higher grades. I'm sure that not only will the teachers, and students feel good about there grades but so will there parents or guardians. Getting good grades is fun and its even better when you can do an after school activity because of it.\\n\\nFrom,\\n\\nSTUDENT_NAME\""
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "max_length = 256"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:20.002395Z",
          "iopub.execute_input": "2025-05-10T16:18:20.002574Z",
          "iopub.status.idle": "2025-05-10T16:18:20.170778Z",
          "shell.execute_reply.started": "2025-05-10T16:18:20.002561Z",
          "shell.execute_reply": "2025-05-10T16:18:20.170276Z"
        },
        "id": "6VS2QYl5YESu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:20.559549Z",
          "iopub.execute_input": "2025-05-10T16:18:20.560029Z",
          "iopub.status.idle": "2025-05-10T16:18:20.564805Z",
          "shell.execute_reply.started": "2025-05-10T16:18:20.560011Z",
          "shell.execute_reply": "2025-05-10T16:18:20.564227Z"
        },
        "id": "awCxzpIRYESu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:21.08211Z",
          "iopub.execute_input": "2025-05-10T16:18:21.082577Z",
          "iopub.status.idle": "2025-05-10T16:18:21.094709Z",
          "shell.execute_reply.started": "2025-05-10T16:18:21.08256Z",
          "shell.execute_reply": "2025-05-10T16:18:21.094145Z"
        },
        "id": "uzDDObxsYESu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load DistilBERT"
      ],
      "metadata": {
        "id": "_4Qpdyu3YESv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistilBERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBERT, self).__init__()\n",
        "        self.distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(768, 2) #the classifier head\n",
        "        )\n",
        "        # the base layers are freezzed since we will keep only the classifier head to be trained\n",
        "        for param in self.distilbert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]   # shape :(batch_size, seq_length, hidden_size)\n",
        "        return self.classifier(cls_output)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:23.519818Z",
          "iopub.execute_input": "2025-05-10T16:18:23.520386Z",
          "iopub.status.idle": "2025-05-10T16:18:23.525194Z",
          "shell.execute_reply.started": "2025-05-10T16:18:23.520362Z",
          "shell.execute_reply": "2025-05-10T16:18:23.524559Z"
        },
        "id": "6CiG0AL6YESw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "rDVew8FmYESx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBERT().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:25.108649Z",
          "iopub.execute_input": "2025-05-10T16:18:25.109349Z",
          "iopub.status.idle": "2025-05-10T16:18:25.378614Z",
          "shell.execute_reply.started": "2025-05-10T16:18:25.109325Z",
          "shell.execute_reply": "2025-05-10T16:18:25.378079Z"
        },
        "id": "YiTPY36nYESx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, optimizer, loss_fn, epochs=3):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1} completed. Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        val_acc = evaluate(model, val_loader)\n",
        "        print(f\"Validation Accuracy: {val_acc:.4f}\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:26.039342Z",
          "iopub.execute_input": "2025-05-10T16:18:26.039572Z",
          "iopub.status.idle": "2025-05-10T16:18:26.045018Z",
          "shell.execute_reply.started": "2025-05-10T16:18:26.039555Z",
          "shell.execute_reply": "2025-05-10T16:18:26.044316Z"
        },
        "id": "Ulp7tBunYESx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
        "        for batch in progress_bar:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:26.789328Z",
          "iopub.execute_input": "2025-05-10T16:18:26.789536Z",
          "iopub.status.idle": "2025-05-10T16:18:26.794202Z",
          "shell.execute_reply.started": "2025-05-10T16:18:26.789521Z",
          "shell.execute_reply": "2025-05-10T16:18:26.793577Z"
        },
        "id": "2eStg2RFYESy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_loader, val_loader, optimizer, loss_fn, epochs=3)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T16:18:29.885938Z",
          "iopub.execute_input": "2025-05-10T16:18:29.886179Z",
          "iopub.status.idle": "2025-05-10T17:03:59.011802Z",
          "shell.execute_reply.started": "2025-05-10T16:18:29.886163Z",
          "shell.execute_reply": "2025-05-10T17:03:59.011076Z"
        },
        "id": "g1v5SqC6YESy",
        "outputId": "189fa518-2846-481d-b4ba-403eabfb40ac",
        "colab": {
          "referenced_widgets": [
            ""
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 1/3:   0%|          | 0/16000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1 completed. Average Loss: 0.1395\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Evaluating:   0%|          | 0/4000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Validation Accuracy: 0.9625\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 2/3:   0%|          | 0/16000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2 completed. Average Loss: 0.0723\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Evaluating:   0%|          | 0/4000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Validation Accuracy: 0.9809\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch 3/3:   0%|          | 0/16000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3 completed. Average Loss: 0.0599\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Evaluating:   0%|          | 0/4000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Validation Accuracy: 0.9844\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = \"/kaggle/working/distilbert_model.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T17:07:11.800619Z",
          "iopub.execute_input": "2025-05-10T17:07:11.800874Z",
          "iopub.status.idle": "2025-05-10T17:07:12.206223Z",
          "shell.execute_reply.started": "2025-05-10T17:07:11.800856Z",
          "shell.execute_reply": "2025-05-10T17:07:12.205561Z"
        },
        "id": "EvGMk5XAYESy",
        "outputId": "95168004-7cbd-4d0f-9fa3-8ab3e1dff35a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Model saved to /kaggle/working/distilbert_model.pth\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_save_path = \"/kaggle/working/distilbert_tokenizer/\"\n",
        "tokenizer.save_pretrained(tokenizer_save_path)\n",
        "print(f\"Tokenizer saved to {tokenizer_save_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T17:07:14.018959Z",
          "iopub.execute_input": "2025-05-10T17:07:14.019222Z",
          "iopub.status.idle": "2025-05-10T17:07:14.038885Z",
          "shell.execute_reply.started": "2025-05-10T17:07:14.019203Z",
          "shell.execute_reply": "2025-05-10T17:07:14.038329Z"
        },
        "id": "USGJdFcgYESz",
        "outputId": "ca222881-22c0-4da7-aeb5-4b715a3c478f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Tokenizer saved to /kaggle/working/distilbert_tokenizer/\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {\n",
        "    'epoch': 3,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss':loss_fn\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, \"/kaggle/working/distilbert_checkpoint1.pth\")\n",
        "print(\"Training checkpoint saved.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T17:08:31.493861Z",
          "iopub.execute_input": "2025-05-10T17:08:31.494574Z",
          "iopub.status.idle": "2025-05-10T17:08:31.901359Z",
          "shell.execute_reply.started": "2025-05-10T17:08:31.494552Z",
          "shell.execute_reply": "2025-05-10T17:08:31.900727Z"
        },
        "id": "nMhpSqN5YESz",
        "outputId": "02834241-63e9-423b-b083-41d34da9b112"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training checkpoint saved.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, model, tokenizer, device, max_length=256):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_ids = encoding['input_ids']\n",
        "        attention_mask = encoding['attention_mask']\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        prediction = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    return \"AI-generated\" if prediction == 1 else \"Human written\", probs.cpu().numpy()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T17:09:34.030232Z",
          "iopub.execute_input": "2025-05-10T17:09:34.030495Z",
          "iopub.status.idle": "2025-05-10T17:09:34.035497Z",
          "shell.execute_reply.started": "2025-05-10T17:09:34.030475Z",
          "shell.execute_reply": "2025-05-10T17:09:34.034789Z"
        },
        "id": "r8VyW1gZYESz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = evaluate(model, val_loader)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T17:30:05.762416Z",
          "iopub.execute_input": "2025-05-10T17:30:05.763093Z",
          "iopub.status.idle": "2025-05-10T17:33:04.366557Z",
          "shell.execute_reply.started": "2025-05-10T17:30:05.76307Z",
          "shell.execute_reply": "2025-05-10T17:33:04.36587Z"
        },
        "id": "WXCTCcL1YESz",
        "outputId": "d3dadb13-7056-487c-d777-bb4b3ec26dc2",
        "colab": {
          "referenced_widgets": [
            ""
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Evaluating:   0%|          | 0/4000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Test Accuracy: 0.9844\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "human= \"\"\"dear  Dr. mike,\n",
        "i hope this mail finds you well, i wanted to ask you regarding my grades in the midterm, also i wanted to mention some concerns from the TA named Osama,\n",
        "he is behaving in a very bad way, making non-sense in assigments and tasks and evaluating us in wrong criteria,\n",
        "also he don't consider the time at all, so please i want you to discuss with him the validty of all of these actions,\n",
        "also the midterm grade, i think that i solved well!! , how can i lose all of this grades in one time\"\"\"\n",
        "\n",
        "ai = \"\"\"Dear Dr. Mike,\n",
        "\n",
        "I hope this email finds you well.\n",
        "\n",
        "I recently received my grades, and I wanted to reach out for some clarification regarding my performance. I would really appreciate any insights you could share on why I received these specific marks, as understanding my mistakes will help me improve in the future.\n",
        "\n",
        "Additionally, I have some concerns regarding the assistance provided by TA Osama. I feel that certain aspects of the grading or support might not have been as clear or fair as expected. If there’s a chance to discuss this, I would be grateful for your perspective on how this might have impacted my performance.\n",
        "\n",
        "Thank you for your time and guidance. I look forward to your response. \"\"\"\n",
        "\n",
        "ai_pred, ai_probs = predict(ai, model, tokenizer, device)\n",
        "human_pred, human_probs = predict(human, model, tokenizer, device)\n",
        "\n",
        "print(\"AI Text Prediction:\", ai_pred)\n",
        "print(f\"AI Text Confidence: {ai_probs[0][1] * 100:.4f}%\")\n",
        "\n",
        "print(\"\\nHuman Text Prediction:\", human_pred)\n",
        "print(f\"Human Text Confidence: {human_probs[0][0] * 100:.4f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T17:26:00.061213Z",
          "iopub.execute_input": "2025-05-10T17:26:00.061444Z",
          "iopub.status.idle": "2025-05-10T17:26:00.097662Z",
          "shell.execute_reply.started": "2025-05-10T17:26:00.061429Z",
          "shell.execute_reply": "2025-05-10T17:26:00.097124Z"
        },
        "id": "Zzs2pbkZYES0",
        "outputId": "e55e7669-549d-423e-9453-58b8454f18ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "AI Text Prediction: AI-generated\nAI Text Confidence: 99.2939%\n\nHuman Text Prediction: Human written\nHuman Text Confidence: 99.9834%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# #to complete training from a checkpoint\n",
        "# checkpoint = torch.load(\"/kaggle/working/distilbert_checkpoint1.pth\")\n",
        "\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# start_epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']"
      ],
      "metadata": {
        "trusted": true,
        "id": "5zEomGQxYES0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink, display\n",
        "\n",
        "display(FileLink('distilbert_model.pth'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-10T18:07:54.323028Z",
          "iopub.execute_input": "2025-05-10T18:07:54.323731Z",
          "iopub.status.idle": "2025-05-10T18:07:54.328531Z",
          "shell.execute_reply.started": "2025-05-10T18:07:54.323708Z",
          "shell.execute_reply": "2025-05-10T18:07:54.327903Z"
        },
        "id": "5k-P6XLPYES1",
        "outputId": "ea679bcb-de95-48e1-c896-eebb7cd26fb0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "/kaggle/working/distilbert_model.pth",
            "text/html": "<a href='distilbert_model.pth' target='_blank'>distilbert_model.pth</a><br>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}